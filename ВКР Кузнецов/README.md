# Анализ повторяющихся последовательностей в играх с помощью алгоритма PrefixSpan

## Требования

### Локальный запуск

- Python 3.10
- venv (виртуальное окружение)

### Использование в docker-контейнере

- Docker
- Docker Compose

## Установка и настройка окружения при локальном запуске

1. Создайте виртуальное окружение:
```bash
python -m venv venv
```

2. Активируйте виртуальное окружение:
- Для Windows:
```bash
venv\Scripts\activate
```
- Для Linux/MacOS:
```bash
source venv/bin/activate
```

3. Установите зависимости:
```bash
python install.py
```

Это установит все необходимые библиотеки и автоматически применит патч для корректной работы PrefixSpan.

## Зависимости

Основные зависимости:
- prefixspan
- numpy
- pandas
- matplotlib
- networkx
- scikit-learn
- python-Levenshtein

Все зависимости указаны в файле `requirements.txt` и устанавливаются автоматически через `install.py`.

## Структура проекта

```
.
├── data/                        # Директория с входными данными
│   ├── data.json              # Исходные последовательности действий
│   ├── encoded_sequences.json  # Закодированные последовательности
│   └── action_mapping.json # Маппинг действий в числовые коды
├── output/                 # Директория для результатов
├── main.py           # Основной скрипт для работы с закодированными данными
├── mainNOencode.py   # Скрипт для работы с незакодированными данными
├── visualization.py  # Модуль визуализации
├── encode_actions.py # Скрипт для кодирования последовательностей
├── start.py         # Скрипт для запуска полного анализа
├── modify.py        # Скрипт для модификации алгоритма (ищет последовательности без пропусков)
├── unmodify.py         # Скрипт для отмены модификации
├── patch.py            # Скрипт для исправления ошибки в библиотеке prefixspan
├── install.py           # Скрипт установки зависимостей
├── requirements.txt     # Список зависимостей
└── README.md           # Документация
```

## Использование

### Подготовка данных

1. Поместите файл с последовательностями действий в формате JSON в директорию `data/` с именем `data.json`
2. Формат данных должен соответствовать следующей структуре:
```json
{
    "player_id": {
        "telemetry_data": "action1: value1; action2: value2; ..."
    }
}
```

### Запуск анализа при локальном запуске

Процесс анализа состоит из двух этапов:

1. **Кодирование последовательностей** (для использования всех опций):
   ```bash
   python encode_actions.py
   ```
   Этот шаг может быть выполнен позднее, из `start.py`
   Этот скрипт преобразует текстовые последовательности действий в числовые коды и создает:
   - `encoded_sequences.json` - закодированные последовательности
   - `action_mapping.json` - маппинг действий в числовые коды

2. **Запуск анализа**:
   ```bash
   python start.py
   ```
   Этот скрипт позволяет осуществить полный анализ, включая:
   - Кодирование данных (для использования всех опций)
   - Выбор варианта анализа
   - Поиск паттернов с помощью алгоритма PrefixSpan
   - Визуализацию результатов
   - Кластеризацию паттернов
   - Статистический анализ

   Или можно запустить отдельные скрипты:
   - Для работы с закодированными данными:
     ```bash
     python main.py
     ```
   - Для работы с незакодированными данными:
     ```bash
     python mainNOencode.py
     ```

### Настройка параметров

В начале скриптов `main.py` и `mainNOencode.py`  можно настроить следующие параметры:

#### Параметры фильтрации последовательностей:
- `CUT_PREFIX_LEN` - количество первых действий для отрезания
- `CUT_UNTIL_ACTION` - действие, с которого начинать анализ
- `MIN_SEQUENCE_LENGTH` - минимальная длина последовательности

#### Параметры фильтрации паттернов:
- `PATTERN_MIN_LENGTH` - минимальная длина паттерна
- `PATTERN_MAX_LENGTH` - максимальная длина паттерна
- `COL` - количество найденных паттернов

#### Параметры визуализации:
- `TOPN` - количество паттернов на гистограмме
- `COEF_NET` - коэффициент для настройки толщины ребер в графе
- `N_clusters_KMeans` - количество кластеров для K-means
- `MAX_DISTANCE_LEVENSHTEIN` - максимальное расстояние для кластеризации по Левенштейну
- `N_clusters_Levenshtein` - количество кластеров для кластеризации по Левенштейну

### Результаты

После выполнения скрипта в директории `output/` будут созданы следующие файлы:
- `patterns.json` - все найденные паттерны
- `pattern_weight.png` - график веса паттернов
- `pattern_network.png` - визуализация сети паттернов
- `pattern_clusters_KMeans.png` - кластеризация методом K-means
- `pattern_clusters_levenshtein.png` - кластеризация по расстоянию Левенштейна
- `pattern_statistics.csv` - статистика паттернов

## Примечания

1. Для корректной работы рекомендуется использовать Python 3.10
2. Используйте виртуальное окружение (venv)
3. При изменении параметров в скриптах перезапустите анализ
4. Результаты сохраняются в директорию `output/`, которая создается автоматически

## Использование с Docker

### Подготовка к работе

1. Убедитесь, что у вас установлены Docker и Docker Compose

2. Поместите файл с данными в директорию `data/`:
```bash
cp ваш_файл.json data/data.json
```

### Запуск и работа с контейнером

1. **Сборка контейнера**:
```bash
docker-compose build
```
Это создаст контейнер

2. **Для работы с интерактивным меню**
```bash
docker compose run --rm prefixspan
```
После этого необходимо выбрать пункт для запуска

Повторить 2 для каждого действия

3. **Запуск конкретного скрипта**:
```bash
# Для работы с закодированными данными
docker-compose run prefixspan python main.py

# Для работы с незакодированными данными
docker-compose run prefixspan python mainNOencode.py

# Для кодирования последовательностей
docker-compose run prefixspan python encode_actions.py
```

4. **Просмотр результатов**:
Все результаты будут доступны в директории `output/` на вашей хост-машине

5. **Остановка контейнера**:
```bash
docker-compose down
```

### Работа с данными

1. **Добавление новых данных**:
   - Поместите новый файл в директорию `data/`
   - Перезапустите контейнер

2. **Просмотр результатов**:
   - Все результаты сохраняются в директории `output/`
   - Файлы доступны сразу после их создания

3. **Настройка параметров**:
   - Параметры можно изменить в файлах `main.py` или `mainNOencode.py`
   - После изменения параметров перезапустите контейнер

### Примечания по работе с Docker

1. **Сохранение данных**:
   - Директории `data/` и `output/` монтируются в контейнер
   - Все изменения в этих директориях сохраняются на хост-машине

2. **Перезапуск контейнера**:
   - При изменении кода или параметров используйте:
   ```bash
   docker-compose up --build
   ```

3. **Очистка**:
   - Для полной очистки контейнера и образов:
   ```bash
   docker-compose down --rmi all
   ```

4. **Логи**:
   - Логи работы скриптов можно просмотреть через:
   ```bash
   docker-compose logs -f
   ```